{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M1L1iW9IghcS"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "class_labels = trainset.classes"
      ],
      "metadata": {
        "id": "mLk6rcwxirEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, 1024)\n",
        "        self.fc5 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32 * 32 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.log_softmax(self.fc5(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iHR4zV0hgi4Q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 및 옵티마이저 설정\n",
        "net = DenseNet()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(10):\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        # 이미지 및 라벨 변환\n",
        "\n",
        "        # 모델 실행 및 손실 계산\n",
        "        outputs = net(images)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "        # 옵티마이저 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}: loss = {loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p_65sOrGgw9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "id": "5Jus4jm1g-FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in class_labels}\n",
        "total_pred = {classname: 0 for classname in class_labels}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[class_labels[label]] += 1\n",
        "            total_pred[class_labels[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "S65sKW5c1Pft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 CNN 모델 정의하기\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # 3개의 입력 채널, 32개의 출력 채널, 3x3 커널 크기, 패딩=1\n",
        "        self.relu1 = nn.ReLU()  # ReLU 활성화 함수\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # 32개의 입력 채널, 64개의 출력 채널, 3x3 커널 크기, 패딩=1\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 커널 크기와 2의 스트라이드를 사용하는 Max Pooling\n",
        "        self.flatten = nn.Flatten()  # 완전 연결 계층(FC Layer)을 통과하기 위한 텐서 평탄화\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # 64x8x8의 입력 특성, 512개의 출력 특성을 가지는 완전 연결층\n",
        "\n",
        "        # 64: 두 번째 합성곱 레이어에서 출력된 채널 수입니다. 즉, 각 위치에서 64개의 특성 맵이 생성되었습니다.\n",
        "        # 8x8: 두 번째 합성곱 레이어의 출력 특성맵의 공간 크기입니다. 이는 입력 이미지의 공간 해상도가 합성곱과 풀링 연산을 거치면서 감소한 결과입니다.\n",
        "\n",
        "        self.relu3 = nn.ReLU()  # ReLU 활성화 함수\n",
        "        self.fc2 = nn.Linear(512, 10)  # 512개의 입력 특성, 10개(레이블 개수) 출력 특성을 가지는 완전 연결층\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # 입력: (N, 3, 32, 32), 출력: (N, 32, 32, 32) N은 배치 사이즈\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool(x)  # 입력: (N, 32, 32, 32), 출력: (N, 32, 16, 16)\n",
        "        x = self.conv2(x)  # 입력: (N, 32, 16, 16), 출력: (N, 64, 16, 16)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool(x)  # 입력: (N, 64, 16, 16), 출력: (N, 64, 8, 8)\n",
        "        x = self.flatten(x)  # 2D 텐서로 평탄화, 입력: (N, 64, 8, 8), 출력: (N, 64*8*8)\n",
        "        x = self.fc1(x)  # 입력: (N, 64*8*8), 출력: (N, 512)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)  # 입력: (N, 512), 출력: (N, 10)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dLKtIaCFaAy6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델의 인스턴스 생성\n",
        "model = CNN()\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "M_e1qSGJWOqp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 학습\n",
        "for epoch in range(10):\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        # 이미지 및 라벨 변환\n",
        "\n",
        "        # 모델 실행 및 손실 계산\n",
        "        outputs = net(images)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "        # 옵티마이저 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}: loss = {loss.item()}\")"
      ],
      "metadata": {
        "id": "h2XWh9GfWT7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total}\")"
      ],
      "metadata": {
        "id": "b91wRr4lWcD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in class_labels}\n",
        "total_pred = {classname: 0 for classname in class_labels}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[class_labels[label]] += 1\n",
        "            total_pred[class_labels[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "PIUgEERWWxiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 디바이스 설정 (GPU 사용 가능하면 GPU, 아니면 CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CIFAR-10 데이터셋에 대한 전처리 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # 무작위로 이미지 좌우 반전\n",
        "    transforms.RandomCrop(32, padding=4),  # 무작위로 이미지 자르기 (32x32 크기로 자르고 패딩은 4로 설정)\n",
        "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 이미지를 정규화\n",
        "])\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 데이터 로더 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
        "\n",
        "# 사전 훈련된 ResNet 모델 불러오기\n",
        "model = resnet18(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)  # CIFAR-10 분류를 위해 마지막의 fully connected layer 수정\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 훈련 루프\n",
        "num_epochs = 50\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 99:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                  f\"Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "# 테스트 루프\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "# 테스트셋의 정확도 출력\n",
        "print(f\"테스트 정확도: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "-aTH4tqjbxT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}